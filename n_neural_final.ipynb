{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lQ3xZmMz0MPq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Training dataset/classification_train.csv')\n",
        "X_train=((data.iloc[0:24000,1:785].values).T)/255\n",
        "Y=data.iloc[:,0].values\n",
        "X_test=((data.iloc[24000:30000,1:785].values).T)/255\n",
        "Y2=data.iloc[0:24000,0].values\n",
        "# one hot encoding\n",
        "\n",
        "Y1=np.zeros((30000,10))\n",
        "for j in range(10):\n",
        "  for i in range(30000):\n",
        "    if (Y[i]==j):\n",
        "      Y1[i,j]=1\n",
        "#now, Y1 is the target values for n neural network\n",
        "\n",
        "#splitting the target values\n",
        "Y_train=(Y1[0:24000,:]).T\n",
        "Y_test=(Y1[24000:30000,:]).T\n",
        "\n",
        "print(np.shape(Y_test))"
      ],
      "metadata": {
        "id": "1vo92Vkk0RDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f95d9f-9d7e-4866-ab03-e865a0e05a08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 6000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def param(dimensions):   \n",
        "    w = {}\n",
        "    b = {}\n",
        "    N = len(dimensions)            \n",
        "    for i in range(1, N):\n",
        "        w[i] = np.random.randn(dimensions[i], dimensions[i-1]) / np.sqrt(dimensions[i-1]) \n",
        "        b[i] = np.zeros((dimensions[i], 1))\n",
        "        \n",
        "    return w,b"
      ],
      "metadata": {
        "id": "20nDlIl70qGy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1,b1=param([784,28,10])\n",
        "print(np.shape(w1[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMSI_6yfEfzk",
        "outputId": "e4f360e4-929f-4624-d078-1270a45c786c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    expZ = np.exp(z)\n",
        "    return expZ/(np.sum(expZ, 0))\n",
        "\n",
        "def relu(Z):\n",
        "    A = np.maximum(0,Z)\n",
        "    return A\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def forward_prop(X, w, b, activation):\n",
        "    a = {}\n",
        "    z = {}\n",
        "    n = len(w)         \n",
        "    a[0] = X\n",
        "    for i in range(1, n):\n",
        "        z[i] = w[i].dot(a[i-1]) + b[i]\n",
        "        if activation == 'tanh':\n",
        "            a[i] = tanh(z[i])\n",
        "        else:\n",
        "            a[i] = relu(z[i])\n",
        "    z[n] = w[n].dot(a[n-1]) + b[n]\n",
        "    a[n] = softmax(z[n])\n",
        "    \n",
        "    return a[n], a ,z"
      ],
      "metadata": {
        "id": "WN38hj9z0vOS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AN, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = -(1./m) * np.sum(Y * np.log(AN))      \n",
        "    cost = np.squeeze(cost)          \n",
        "    return cost"
      ],
      "metadata": {
        "id": "CARMXstt02TH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d_relu(Z):\n",
        "    return np.array(Z > 0, dtype = 'float')\n",
        "\n",
        "def d_tanh(x):\n",
        "    return (1 - np.power(np.tanh(x), 2))\n",
        "\n",
        "def backward_prop(an, Y, w, b, a, z, activation):\n",
        "    dw = {}\n",
        "    db = {}\n",
        "    dz = {}\n",
        "    n = len(w)\n",
        "    m = a[n].shape[1]\n",
        "\n",
        "    dz[n] = an - Y\n",
        "    dw[n] = 1./m * np.dot(dz[n],a[n-1].T)\n",
        "    db[n] = 1./m * np.sum(dz[n], axis = 1, keepdims = True)\n",
        "    for i in reversed(range(1, n)):\n",
        "        if (activation == 'tanh'):\n",
        "            dz[i] = np.dot(w[i+1].T,dz[i+1])*d_tanh(a[i])\n",
        "        else:\n",
        "            dz[i] = np.dot(w[i+1].T,dz[i+1])*d_relu(a[i])    \n",
        "        dw[i] = 1./m * np.dot(dz[i],a[i-1].T)\n",
        "        db[i] = 1./m * np.sum(dz[i], axis = 1, keepdims = True)\n",
        "\n",
        "    return dw , db"
      ],
      "metadata": {
        "id": "CAibIJoV05D9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(w ,b ,dw, db, alpha):\n",
        "    L = len(w)  \n",
        "    for i in range(L):\n",
        "        w[i+1] = w[i+1] - alpha * dw[i+1]\n",
        "        b[i+1] = b[i+1] - alpha * db[i+1]\n",
        "    return w,b"
      ],
      "metadata": {
        "id": "AEj41WPm07kZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, w, b, activation):\n",
        "    m = X.shape[1]\n",
        "    an, a, z = forward_prop(X, w, b, activation)\n",
        "    y = np.argmax(y, 0)\n",
        "    an = np.argmax(an, 0)\n",
        "    return np.round(np.sum((an == y)/m), 4)"
      ],
      "metadata": {
        "id": "3N__iMGY0-oH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X, Y, dimensions, alpha , activation , num_iterations):\n",
        "    np.random.seed(1)\n",
        "    costs = []                 \n",
        "    w,b = param(dimensions)\n",
        "    n = len(w)\n",
        "    for i in range(0, num_iterations):\n",
        "        an, a, z = forward_prop(X, w, b, activation)\n",
        "        cost = compute_cost(an, Y)\n",
        "        costs.append(cost)\n",
        "        dw, db = backward_prop(an , Y, w, b, a, z, activation)\n",
        "        w,b = update_parameters(w, b, dw, db, alpha)\n",
        "        if (i % 100) == 0:\n",
        "            print(\"iterations: \",i, \"cost: \",np.round(cost, 4), \"test accuracy: \", (predict(X_test, Y_test, w, b, activation))*100,\"%\")    \n",
        "    t = np.arange(0, num_iterations)\n",
        "    plt.plot(t, costs)\n",
        "    plt.show()\n",
        "    return w,b"
      ],
      "metadata": {
        "id": "Z9T1uJSH1BXR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=int(input(\"enter the value of number of hidden layers: \"))\n",
        "dim=[0]*(n+2)\n",
        "dim[0]=784\n",
        "dim[n+1]=10\n",
        "for i in range(n):\n",
        "    dim[i+1]=int(input(\"enter the neurons in hidden layer \"))\n",
        "alpha = 0.035\n",
        "num = 4001\n",
        "w, b = model(X_train, Y_train, dim, alpha, 'relu', num)"
      ],
      "metadata": {
        "id": "7Ifw_wkZ1Cq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}